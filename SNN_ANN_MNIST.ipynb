{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e3ab7f-0d9c-449e-b3db-ab7f01501cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba9c782-f3bf-4fad-a557-b72f1f6f96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, input_size=784, hidden_sizes=[512, 256], output_size=10):\n",
    "        self.model = self.build_model(input_size, hidden_sizes, output_size)\n",
    "    \n",
    "    def build_model(self, input_size, hidden_sizes, output_size):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(hidden_sizes[0], activation='relu', input_shape=(input_size,)))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        for hidden_size in hidden_sizes[1:]:\n",
    "            model.add(layers.Dense(hidden_size, activation='relu'))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(output_size, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=15, batch_size=128):\n",
    "        start_time = time.time()\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train, validation_data=(X_val, y_val),\n",
    "            epochs=epochs, batch_size=batch_size, verbose=1\n",
    "        )\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\nANN Training time: {training_time:.2f} seconds\")\n",
    "        return history, training_time\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X, verbose=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c215c35-d182-4539-ac33-097a38400731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNtoSNN:\n",
    "    def __init__(self, ann_model, timesteps=100):\n",
    "        self.timesteps = timesteps\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # Extract weights from Dense layers only\n",
    "        for layer in ann_model.layers:\n",
    "            if isinstance(layer, layers.Dense):\n",
    "                w, b = layer.get_weights()\n",
    "                self.weights.append(w)\n",
    "                self.biases.append(b)\n",
    "        \n",
    "        print(f\"Extracted {len(self.weights)} layers from ANN\")\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            print(f\"  Layer {i}: Weight shape {w.shape}, Bias shape {b.shape}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through SNN with rate-based encoding\"\"\"\n",
    "        # Rate-based input encoding (normalized pixel values as firing rates)\n",
    "        current_activity = x.copy()\n",
    "        \n",
    "        # Process through all layers except the last one\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            # Weighted sum\n",
    "            activation = np.dot(current_activity, self.weights[i]) + self.biases[i]\n",
    "            # ReLU activation (mimics spiking behavior)\n",
    "            current_activity = np.maximum(0, activation)\n",
    "            # Normalize to keep values in reasonable range\n",
    "            if np.max(current_activity) > 0:\n",
    "                current_activity = current_activity / np.max(current_activity)\n",
    "        \n",
    "        # Output layer - no normalization\n",
    "        output_activation = np.dot(current_activity, self.weights[-1]) + self.biases[-1]\n",
    "        \n",
    "        return output_activation\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict single sample\"\"\"\n",
    "        output = self.forward(x)\n",
    "        return np.argmax(output)\n",
    "    \n",
    "    def predict_batch(self, X):\n",
    "        \"\"\"Predict multiple samples\"\"\"\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            predictions.append(self.predict(X[i]))\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e251cd-c74e-4501-b232-ebf201a62b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNtoSNN_Spiking:\n",
    "    \n",
    "    def __init__(self, ann_model, timesteps=100, threshold=1.0):\n",
    "        self.timesteps = timesteps\n",
    "        self.threshold = threshold\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        \n",
    "        for layer in ann_model.layers:\n",
    "            if isinstance(layer, layers.Dense):\n",
    "                w, b = layer.get_weights()\n",
    "                self.weights.append(w)\n",
    "                self.biases.append(b)\n",
    "        \n",
    "        print(f\"\\nSpiking SNN: Extracted {len(self.weights)} layers\")\n",
    "\n",
    "    def poisson_encoding(self, x, timesteps):\n",
    "        \n",
    "        spikes = np.random.rand(timesteps, len(x)) < np.clip(x, 0, 1)\n",
    "        return spikes.astype(float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        spike_train = self.poisson_encoding(x, self.timesteps)\n",
    "        \n",
    "        \n",
    "        n_layers = len(self.weights)\n",
    "        membrane_potentials = [np.zeros(w.shape[1]) for w in self.weights]\n",
    "        spike_counts = [np.zeros(w.shape[1]) for w in self.weights]\n",
    "        \n",
    "        \n",
    "        for t in range(self.timesteps):\n",
    "            current_spikes = spike_train[t]\n",
    "            \n",
    "            \n",
    "            for layer_idx in range(n_layers):\n",
    "                \n",
    "                weighted_input = np.dot(current_spikes, self.weights[layer_idx])\n",
    "                membrane_potentials[layer_idx] += weighted_input\n",
    "                \n",
    "               \n",
    "                membrane_potentials[layer_idx] += self.biases[layer_idx] / self.timesteps\n",
    "                \n",
    "               \n",
    "                membrane_potentials[layer_idx] = np.maximum(0, membrane_potentials[layer_idx])\n",
    "                \n",
    "                \n",
    "                spikes = (membrane_potentials[layer_idx] >= self.threshold).astype(float)\n",
    "                spike_counts[layer_idx] += spikes\n",
    "                \n",
    "               \n",
    "                membrane_potentials[layer_idx] = np.where(\n",
    "                    spikes > 0,\n",
    "                    0,  \n",
    "                    membrane_potentials[layer_idx]\n",
    "                )\n",
    "                \n",
    "               \n",
    "                current_spikes = spikes\n",
    "        \n",
    "     \n",
    "        return spike_counts[-1]\n",
    "\n",
    "    def predict(self, x):\n",
    "      \n",
    "        spike_counts = self.forward(x)\n",
    "        return np.argmax(spike_counts)\n",
    "    \n",
    "    def predict_batch(self, X):\n",
    "       \n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"  Processing sample {i}/{len(X)}...\", end='\\r')\n",
    "            predictions.append(self.predict(X[i]))\n",
    "        print()\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e9ca092-ccab-491c-a80b-53b23973ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(ann_history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "  \n",
    "    ax1.plot(ann_history.history['accuracy'], label='Train Acc', marker='o', linewidth=2)\n",
    "    ax1.plot(ann_history.history['val_accuracy'], label='Val Acc', marker='s', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax1.set_title('ANN Training Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "\n",
    "    ax2.plot(ann_history.history['loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "    ax2.plot(ann_history.history['val_loss'], label='Val Loss', marker='s', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title('ANN Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ann_training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bff40293-2bd4-4d86-8d72-ca86f95637d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_comparison(results):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    models = list(results.keys())\n",
    "    accuracies = list(results.values())\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "    \n",
    "    bars = ax.bar(models, accuracies, color=colors[:len(models)], \n",
    "                  alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title('Model Accuracy Comparison', fontsize=16, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "  \n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{acc:.4f}',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ce12ea-b90e-4e0c-9fb4-bb70c1f33a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_predictions(X_test, y_test, ann_pred, snn_pred, n_samples=10):\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(20, 5))\n",
    "    indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "    \n",
    "    for idx, i in enumerate(indices):\n",
    "        img = X_test[i].reshape(28, 28)\n",
    "        \n",
    "    \n",
    "        axes[0, idx].imshow(img, cmap='gray')\n",
    "        axes[0, idx].axis('off')\n",
    "        color = 'green' if ann_pred[i] == y_test[i] else 'red'\n",
    "        axes[0, idx].set_title(f'ANN: {ann_pred[i]}\\nTrue: {y_test[i]}', \n",
    "                               color=color, fontweight='bold', fontsize=10)\n",
    "        \n",
    "      \n",
    "        axes[1, idx].imshow(img, cmap='gray')\n",
    "        axes[1, idx].axis('off')\n",
    "        color = 'green' if snn_pred[i] == y_test[i] else 'red'\n",
    "        axes[1, idx].set_title(f'SNN: {snn_pred[i]}\\nTrue: {y_test[i]}', \n",
    "                               color=color, fontweight='bold', fontsize=10)\n",
    "    \n",
    "    fig.text(0.02, 0.75, 'ANN', fontsize=14, fontweight='bold', rotation=90, va='center')\n",
    "    fig.text(0.02, 0.25, 'SNN', fontsize=14, fontweight='bold', rotation=90, va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13539d3-5b6c-44b8-9be5-882c643d4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ANN to SNN Conversion - MNIST Digit Classification\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "  \n",
    "    print(\"\\n[1] Loading MNIST dataset...\")\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train = X_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "    X_test = X_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "    y_train_cat = to_categorical(y_train, 10)\n",
    "    y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "  \n",
    "    n_train, n_test = 20000, 2000\n",
    "    X_train_subset, y_train_subset = X_train[:n_train], y_train[:n_train]\n",
    "    y_train_cat_subset = y_train_cat[:n_train]\n",
    "    X_test_subset, y_test_subset = X_test[:n_test], y_test[:n_test]\n",
    "    y_test_cat_subset = y_test_cat[:n_test]\n",
    "\n",
    "    print(f\"Training samples: {n_train}, Test samples: {n_test}\")\n",
    "\n",
    "   \n",
    "    print(\"\\n[2] Training ANN...\")\n",
    "    ann = ANN(input_size=784, hidden_sizes=[256, 128], output_size=10)\n",
    "    ann_history, ann_time = ann.train(\n",
    "        X_train_subset, y_train_cat_subset, \n",
    "        X_test_subset, y_test_cat_subset, \n",
    "        epochs=10, batch_size=128\n",
    "    )\n",
    "    \n",
    "  \n",
    "    print(\"\\n[3] Evaluating ANN...\")\n",
    "    ann_loss, ann_accuracy = ann.evaluate(X_test_subset, y_test_cat_subset)\n",
    "    ann_predictions = ann.predict(X_test_subset)\n",
    "    print(f\"✓ ANN Test Accuracy: {ann_accuracy:.4f}\")\n",
    "\n",
    "  \n",
    "    print(\"\\n[4] Converting ANN to Rate-based SNN...\")\n",
    "    snn_rate = ANNtoSNN(ann.model, timesteps=100)\n",
    "    \n",
    "    print(\"Evaluating Rate-based SNN...\")\n",
    "    snn_rate_predictions = snn_rate.predict_batch(X_test_subset)\n",
    "    snn_rate_accuracy = np.mean(snn_rate_predictions == y_test_subset)\n",
    "    print(f\"✓ Rate-based SNN Test Accuracy: {snn_rate_accuracy:.4f}\")\n",
    "\n",
    "  \n",
    "    print(\"\\n[5] Converting ANN to Spiking SNN...\")\n",
    "    \n",
    "   \n",
    "    timesteps_to_use = 100\n",
    "    threshold_to_use = 1.0  \n",
    "    \n",
    "    snn_spike = ANNtoSNN_Spiking(ann.model, timesteps=timesteps_to_use, threshold=threshold_to_use)\n",
    "    \n",
    "    print(f\"Configuration: timesteps={timesteps_to_use}, threshold={threshold_to_use}\")\n",
    "    print(\"Evaluating Spiking SNN (this may take a moment)...\")\n",
    "    snn_spike_predictions = snn_spike.predict_batch(X_test_subset)\n",
    "    snn_spike_accuracy = np.mean(snn_spike_predictions == y_test_subset)\n",
    "    print(f\"✓ Spiking SNN Test Accuracy: {snn_spike_accuracy:.4f}\")\n",
    "    \n",
    "    \n",
    "    if snn_spike_accuracy < 0.75:\n",
    "        print(\"\\n If accuracy is too low, try threshold=0.5 or timesteps=150\")\n",
    "    elif snn_spike_accuracy >= 0.80:\n",
    "        print(\"\\n✓ Good SNN conversion! Spiking accuracy within expected range.\")\n",
    "\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ANN Accuracy:              {ann_accuracy:.4f}\")\n",
    "    print(f\"Rate-based SNN Accuracy:   {snn_rate_accuracy:.4f} (drop: {(ann_accuracy - snn_rate_accuracy):.4f})\")\n",
    "    print(f\"Spiking SNN Accuracy:      {snn_spike_accuracy:.4f} (drop: {(ann_accuracy - snn_spike_accuracy):.4f})\")\n",
    "    print(f\"Training Time:             {ann_time:.2f} seconds\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    " \n",
    "  \n",
    "    plot_training_history(ann_history)\n",
    "    \n",
    "    results = {\n",
    "        'ANN': ann_accuracy,\n",
    "        'Rate SNN': snn_rate_accuracy,\n",
    "        'Spike SNN': snn_spike_accuracy\n",
    "    }\n",
    "    plot_accuracy_comparison(results)\n",
    "    plot_sample_predictions(X_test_subset, y_test_subset, \n",
    "                           ann_predictions, snn_rate_predictions, n_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a098a-7560-40be-8932-b186de3344aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ANN to SNN Conversion - MNIST Digit Classification\n",
      "======================================================================\n",
      "\n",
      "[1] Loading MNIST dataset...\n",
      "Training samples: 20000, Test samples: 2000\n",
      "\n",
      "[2] Training ANN...\n",
      "Epoch 1/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7103 - loss: 0.9553 - val_accuracy: 0.9160 - val_loss: 0.2901\n",
      "Epoch 2/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2511 - val_accuracy: 0.9315 - val_loss: 0.2159\n",
      "Epoch 3/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.1828 - val_accuracy: 0.9460 - val_loss: 0.1785\n",
      "Epoch 4/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.1236 - val_accuracy: 0.9490 - val_loss: 0.1703\n",
      "Epoch 5/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9699 - loss: 0.1012 - val_accuracy: 0.9515 - val_loss: 0.1463\n",
      "Epoch 6/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9741 - loss: 0.0846 - val_accuracy: 0.9625 - val_loss: 0.1344\n",
      "Epoch 7/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0685 - val_accuracy: 0.9650 - val_loss: 0.1308\n",
      "Epoch 8/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0533 - val_accuracy: 0.9650 - val_loss: 0.1247\n",
      "Epoch 9/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0451 - val_accuracy: 0.9640 - val_loss: 0.1319\n",
      "Epoch 10/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0384 - val_accuracy: 0.9625 - val_loss: 0.1320\n",
      "\n",
      "ANN Training time: 11.57 seconds\n",
      "\n",
      "[3] Evaluating ANN...\n",
      "✓ ANN Test Accuracy: 0.9625\n",
      "\n",
      "[4] Converting ANN to Rate-based SNN...\n",
      "Extracted 3 layers from ANN\n",
      "  Layer 0: Weight shape (784, 256), Bias shape (256,)\n",
      "  Layer 1: Weight shape (256, 128), Bias shape (128,)\n",
      "  Layer 2: Weight shape (128, 10), Bias shape (10,)\n",
      "Evaluating Rate-based SNN...\n",
      "✓ Rate-based SNN Test Accuracy: 0.9610\n",
      "\n",
      "[5] Converting ANN to Spiking SNN...\n",
      "\n",
      "Spiking SNN: Extracted 3 layers\n",
      "Configuration: timesteps=100, threshold=1.0\n",
      "Evaluating Spiking SNN (this may take a moment)...\n",
      "  Processing sample 400/2000..."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9a93a-98a5-4e22-89e7-95c11249230a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Torch)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
